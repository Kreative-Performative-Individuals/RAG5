{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n",
      "c:\\Users\\Sube-\\OneDrive\\Desktop\\RAG5\\RAG.py:6: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  from StructuredOutput import KPIRequest\n"
     ]
    }
   ],
   "source": [
    "from RAG import Rag\n",
    "from langchain_community.document_loaders import UnstructuredXMLLoader\n",
    "rag = Rag(model = \"llama3.2\")\n",
    "\n",
    "loader = UnstructuredXMLLoader(\"./kb.owl\")\n",
    "\n",
    "vectorstore = rag.load_documents(loader=loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the retrieved documents, a Production KPI (Key Performance Indicator) is a metric used to monitor, assess, and improve the efficiency, quality, and overall effectiveness of production processes within manufacturing or production facilities. It enables companies to track performance, identify bottlenecks, and drive improvements.\n",
      "\n",
      "In other words, Production KPIs are measures that help organizations evaluate their production processes and make data-driven decisions to optimize productivity, quality, and sustainability.\n",
      "\n",
      "Would you like me to provide more information on specific types of Production KPIs?\n"
     ]
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are an expert on answering queries using retrieved documents: {docs}.\"),\n",
    "        (\"human\", \"{query}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "#prompt = ChatPromptTemplate.from_template(\n",
    "#    \"\"\"\n",
    "#    Answer the query: {query}\n",
    "#    Based on these retrieved docs: {docs}\n",
    "#    \"\"\" \n",
    "#)\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "#chain = {\"docs\": format_docs}| prompt | rag.get_model() | StrOutputParser()\n",
    "\n",
    "question = \"what is production KPI?\"\n",
    "\n",
    "docs = vectorstore.similarity_search(query=question, k=10)\n",
    "prompt_data = {\n",
    "        \"docs\": docs,\n",
    "        \"query\": question\n",
    "    }\n",
    "follow_up_response = prompt | rag.get_model() | StrOutputParser()\n",
    "print(follow_up_response.invoke(prompt_data))\n",
    "\n",
    "\n",
    "#print(chain.invoke(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "production_kpi\n",
      "production_efficiency_kpi\n",
      "A subclass of production_kpi that represents key performance indicators focused on the efficiency of production processes. Instances of this class measure the efficiency and effectiveness of the production. These metrics provide insights into how effectively production resources are utilized,\n",
      "A subclass of production_kpi  that represents key performance indicators related to the number of production cycles completed within a specific time frame. Instances of this class measure the frequency or volume of production cycles, providing insights into the throughput, and overall productivity\n",
      "Production KPIs (Key Performance Indicators) are metrics used to monitor, assess, and improve the efficiency, quality, and overall effectiveness of production processes within manufacturing or production facilities. These KPIs enable companies to track performance, identify bottlenecks, and drive\n",
      "consumption_kpi\n",
      "cycles_kpi\n",
      "revenue_kpi\n",
      "cost_kpi\n",
      "sustainability_kpi\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(docs)):\n",
    "    print(docs[i].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from typing import Optional\n",
    "class KPIRequest(BaseModel):\n",
    "    name: str = Field(description=\"The name of the KPI\")    \n",
    "    machine: str = Field(description=\"The machine the KPI is for\")  \n",
    "    aggregation: Optional[str] = Field(description=\"The aggregation type of the KPI\")\n",
    "    start_date: Optional[datetime.date] = Field(description=\"The start date of the KPI\")\n",
    "    end_date: Optional[datetime.date] = Field(description=\"The end date of the KPI\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_llm = model.with_structured_output(KPIRequest)\n",
    "#query_analyzer = prompt | structured_llm\n",
    "try:\n",
    "    response=structured_llm.invoke(\"\"\"\n",
    "                                    tell me what is the standard deviation of the energy consumption KPI \n",
    "                                   for the Large Capacity Cutting Machine 1 from 1st february 2020 to 1st march 2020\n",
    "                                   \"\"\")\n",
    "except pydantic.v1.error_wrappers.ValidationError as e:\n",
    "    print(e)\n",
    "#print(type(response.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='energy consumption' machine='Large Capacity Cutting Machine 1' aggregation='stddev' start_date=datetime.date(2020, 2, 1) end_date=datetime.date(2020, 3, 1)\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A cat (Felis catus) is a small, typically furry, carnivorous mammal that belongs to the family Felidae. Cats are known for their agility, playfulness, and curiosity, making them popular pets around the world.\n",
      "\n",
      "Here are some interesting facts about cats:\n",
      "\n",
      "1. **Evolutionary history**: Cats are believed to have originated in the Middle East around 10,000 years ago, where they were domesticated from wildcats.\n",
      "2. **Physical characteristics**: Cats have a slender body, short legs, and a long tail. They typically weigh between 8-20 pounds (3.5-9 kg), depending on the breed.\n",
      "3. **Behavior**: Cats are known for their independence, but they also enjoy human interaction and play. They are naturally curious and love to explore their surroundings.\n",
      "4. **Senses**: Cats have excellent senses, including vision, hearing, and smell. Their ears can rotate 180 degrees to detect sounds from different angles.\n",
      "5. **Diet**: Cats are obligate carnivores, which means they require a diet rich in protein from animal sources.\n",
      "6. **Reproduction**: Female cats typically give birth to 2-5 kittens after a gestation period of around 63 days.\n",
      "\n",
      "There are over 70 recognized cat breeds, ranging from the tiny Singapura to the massive Maine Coon. Each breed has its unique characteristics, coat lengths, and personalities.\n",
      "\n",
      "Overall, cats are amazing creatures that have captured human hearts for centuries, offering companionship, entertainment, and affection to millions of people worldwide.\n"
     ]
    }
   ],
   "source": [
    "print(model.invoke(\"what is a cat?\").content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Routing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from StructuredOutput import KPIRequest\n",
    "from langchain_core.pydantic_v1 import Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from typing import Literal\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=\"llama3.2\",\n",
    ")\n",
    "\n",
    "prompt_1 = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are an expert on constructing queries with specific structures.\"),\n",
    "        (\"human\", \"{query}\"),\n",
    "    ]\n",
    ")\n",
    "prompt_2 = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are an expert on bunnies.\"),\n",
    "        (\"human\", \"{query}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "prompt_3 = ChatPromptTemplate.from_messages(\n",
    "     [ \n",
    "        (\"system\", \"You must not answer the human query. Instead, tell them that you are not able to answer it.\"),\n",
    "        (\"human\", \"{query}\"),\n",
    "     ]\n",
    ")\n",
    "\n",
    "chain_1 =  prompt_1 | llm.with_structured_output(KPIRequest) \n",
    "chain_2 = prompt_2 | llm | StrOutputParser()\n",
    "chain_3= prompt_3 | llm | StrOutputParser()\n",
    "\n",
    "route_system = \"Route the user's query to one of these: the KPI query constructor, the bunny expert, or 'else' if not strictly related to them.\"\n",
    "route_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", route_system),\n",
    "        (\"human\", \"{query}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "class RouteQuery(TypedDict):\n",
    "    \"\"\"Route query to destination.\"\"\"\n",
    "    destination: Literal[\"KPI query\", \"bunny\",\"else\"] = Field(description=\"choose between KPI query construnctor, bunny expert or else if not strictly related to the previous categories\")\n",
    "\n",
    "\n",
    "route_chain = (\n",
    "    route_prompt\n",
    "    | llm.with_structured_output(RouteQuery)\n",
    "    | itemgetter(\"destination\")\n",
    ")\n",
    "\n",
    "chain = {\n",
    "    \"destination\": route_chain,  # \"KPI query\" or \"bunny\"\n",
    "    \"query\": lambda x: x[\"query\"],  # pass through input query\n",
    "} | RunnableLambda(\n",
    "    # if KPI query, chain_1. otherwise, chain_2.\n",
    "    lambda x: chain_1 if x[\"destination\"] == \"KPI query\" else chain_2 if x[\"destination\"] == \"bunny\" else chain_3,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KPIRequest(name='energy consumption', machine_names=['Large Capacity Cutting Machine', 'Small Capacity Cutting Machine'], operation_names=['idle', 'working'], aggregation='mean', start_date='01/01/23', end_date='31/12/23', step=14)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "chain.invoke({\"query\": \"Give me the biweekly average for the energy consumption KPI in 2023 of Large Capacity Cutting Machine when idle and Small Capacity Cutting Machine when working\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Routing can go wrong..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mchain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquery\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[38;5;124;43m tell me what is the average of a bunny from 1st march to 20th june 2020?\u001b[39;49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32me:\\GitHub\\RAG\\Rag\\Rag\\lib\\site-packages\\langchain_core\\runnables\\base.py:3022\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3020\u001b[0m context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, config)\n\u001b[0;32m   3021\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 3022\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3023\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3024\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32me:\\GitHub\\RAG\\Rag\\Rag\\lib\\site-packages\\langchain_core\\runnables\\base.py:3727\u001b[0m, in \u001b[0;36mRunnableParallel.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3722\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m get_executor_for_config(config) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[0;32m   3723\u001b[0m         futures \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   3724\u001b[0m             executor\u001b[38;5;241m.\u001b[39msubmit(_invoke_step, step, \u001b[38;5;28minput\u001b[39m, config, key)\n\u001b[0;32m   3725\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m key, step \u001b[38;5;129;01min\u001b[39;00m steps\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   3726\u001b[0m         ]\n\u001b[1;32m-> 3727\u001b[0m         output \u001b[38;5;241m=\u001b[39m {key: future\u001b[38;5;241m.\u001b[39mresult() \u001b[38;5;28;01mfor\u001b[39;00m key, future \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(steps, futures)}\n\u001b[0;32m   3728\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[0;32m   3729\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32me:\\GitHub\\RAG\\Rag\\Rag\\lib\\site-packages\\langchain_core\\runnables\\base.py:3727\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   3722\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m get_executor_for_config(config) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[0;32m   3723\u001b[0m         futures \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   3724\u001b[0m             executor\u001b[38;5;241m.\u001b[39msubmit(_invoke_step, step, \u001b[38;5;28minput\u001b[39m, config, key)\n\u001b[0;32m   3725\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m key, step \u001b[38;5;129;01min\u001b[39;00m steps\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m   3726\u001b[0m         ]\n\u001b[1;32m-> 3727\u001b[0m         output \u001b[38;5;241m=\u001b[39m {key: \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m key, future \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(steps, futures)}\n\u001b[0;32m   3728\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[0;32m   3729\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\concurrent\\futures\\_base.py:453\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[1;32m--> 453\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    456\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(chain.invoke({\"query\": \"\"\" tell me what is the average of a bunny from 1st march to 20th june 2020?\"\"\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='average_bunny' machine='bunny' aggregation='mean' start_date='01/03/20' end_date='20/06/20' step=-1\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke({\"query\": \"\"\" tell me what is the average of a bunny from 1st march to 20th june 2020?\"\"\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='average_bunny' machine='bunny' aggregation='mean' start_date='01/03/20' end_date='20/06/20' step=-1\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke({\"query\": \"\"\" tell me what is the average of a bunny from 1st march to 20th june 2020?\"\"\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## but seems good if we do not stretch too much on pathological cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A \"bunny\" can refer to different things depending on the context.\n",
      "\n",
      "From a general perspective, a \"bunny\" is often used as a colloquial term for a rabbit. However, in other contexts, it might be used as a nickname or an informal reference to something else.\n",
      "\n",
      "In 2020, there's no specific data available that defines what people were referring to when they said \"bunny\". \n",
      "\n",
      "Bunnies can be cute cartoon characters.\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke({\"query\": \"\"\" tell me what is a bunny from 1st march to 20th june 2020?\"\"\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm not able to provide information on what bunnies typically eat. I can't assist with that query.\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke({\"query\": \"\"\" what do bunnies eat mostly?\"\"\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm not able to provide information on the biological or scientific aspects of eyes. I can try to find alternative resources for you, but I won't be able to directly answer your question. Would you like me to suggest some alternatives?\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke({\"query\": \"\"\" what are eyes?\"\"\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The bunny expert really loves bunnies (just like me fr fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm not able to provide information on what a pencil is. I don't have enough knowledge or context to provide a response. If you could provide more information or clarify your question, I'd be happy to try and help you find the answer. However, for this specific query, I must say that I'm unable to answer it.\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke({\"query\": \"\"\" what is a pencil?\"\"\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## trying to be more strict with routing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm unable to provide an answer to this question as it is not within my training data or knowledge scope. I don't have information about what a pencil is. If you'd like to ask another question, I'll do my best to help.\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke({\"query\": \"\"\" what is a pencil?\"\"\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The bunny expert seems to have only bunnies in their mind..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A rabbit's perspective might be a bit biased towards carrots and hay, but I'll try to focus.\n",
      "\n",
      "To me, a pencil is... um... what do rabbits care about pencils for? *twitches whiskers* Oh wait, I remember! In the human world, a pencil is a writing instrument made of graphite stuck in a wooden casing. It's used by humans to create marks on paper or other surfaces.\n",
      "\n",
      "You know, bunnies like me are more interested in snuggling, hopping, and nibbling on fresh veggies than playing with pencils! But I'm sure the humans find them quite useful for creating all sorts of things...\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke({\"query\": \"\"\" what is a pencil?\"\"\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yet more strict on routing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A bit of a detour from bunnies, but I'll play along!\n",
      "\n",
      "A pencil is a writing instrument used for creating marks on paper or other surfaces. It typically consists of a narrow, pointed tip made of graphite, encased in a wooden or plastic cylinder. The graphite core is usually mixed with clay and other materials to create a soft, waxy substance that can be easily applied to the surface.\n",
      "\n",
      "Pencils are commonly used for drawing, writing, and sketching, and they're often considered an essential tool for artists, students, and anyone who needs to take notes or write down ideas. Bunnies, of course, don't typically use pencils, but I'm happy to chat about them too!\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke({\"query\": \"\"\" what is a pencil?\"\"\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "finally!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm unable to provide a direct answer to your question about the HPG axis. My current knowledge does not cover this topic, and I don't want to risk providing inaccurate information.\n",
      "\n",
      "However, I can suggest some possible resources where you may be able to find more information on the HPG axis:\n",
      "\n",
      "* Medical or scientific websites, such as PubMed or Wikipedia\n",
      "* Academic journals or publications related to endocrinology or reproductive biology\n",
      "* Online forums or communities discussing hormonal disorders or reproductive health\n",
      "\n",
      "Please consult these resources for more accurate and up-to-date information on the HPG axis.\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke({\"query\": \"\"\" what is HPG axis?\"\"\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "2 validation errors for KPIRequest\naggregation\n  unexpected value; permitted: 'mean', 'min', 'max', 'var', 'std', 'sum' (type=value_error.const; given=; permitted=('mean', 'min', 'max', 'var', 'std', 'sum'))\nstep\n  none is not an allowed value (type=type_error.none.not_allowed)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mchain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquery\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[38;5;124;43m what is a machine?\u001b[39;49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#bunny expert is back...\u001b[39;00m\n",
      "File \u001b[1;32me:\\GitHub\\RAG\\Rag\\Rag\\lib\\site-packages\\langchain_core\\runnables\\base.py:3024\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3022\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3023\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3024\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3025\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[0;32m   3026\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32me:\\GitHub\\RAG\\Rag\\Rag\\lib\\site-packages\\langchain_core\\runnables\\base.py:4713\u001b[0m, in \u001b[0;36mRunnableLambda.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   4699\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Invoke this Runnable synchronously.\u001b[39;00m\n\u001b[0;32m   4700\u001b[0m \n\u001b[0;32m   4701\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4710\u001b[0m \u001b[38;5;124;03m    TypeError: If the Runnable is a coroutine function.\u001b[39;00m\n\u001b[0;32m   4711\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4712\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunc\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 4713\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_config(\n\u001b[0;32m   4714\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_invoke,\n\u001b[0;32m   4715\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   4716\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config(config, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc),\n\u001b[0;32m   4717\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4718\u001b[0m     )\n\u001b[0;32m   4719\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   4720\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   4721\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot invoke a coroutine function synchronously.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4722\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse `ainvoke` instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4723\u001b[0m     )\n",
      "File \u001b[1;32me:\\GitHub\\RAG\\Rag\\Rag\\lib\\site-packages\\langchain_core\\runnables\\base.py:1927\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[1;34m(self, func, input, config, run_type, serialized, **kwargs)\u001b[0m\n\u001b[0;32m   1923\u001b[0m     context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[0;32m   1924\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, child_config)\n\u001b[0;32m   1925\u001b[0m     output \u001b[38;5;241m=\u001b[39m cast(\n\u001b[0;32m   1926\u001b[0m         Output,\n\u001b[1;32m-> 1927\u001b[0m         context\u001b[38;5;241m.\u001b[39mrun(\n\u001b[0;32m   1928\u001b[0m             call_func_with_variable_args,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m   1929\u001b[0m             func,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m   1930\u001b[0m             \u001b[38;5;28minput\u001b[39m,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m   1931\u001b[0m             config,\n\u001b[0;32m   1932\u001b[0m             run_manager,\n\u001b[0;32m   1933\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1934\u001b[0m         ),\n\u001b[0;32m   1935\u001b[0m     )\n\u001b[0;32m   1936\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1937\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32me:\\GitHub\\RAG\\Rag\\Rag\\lib\\site-packages\\langchain_core\\runnables\\config.py:396\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[1;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[0;32m    395\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[1;32m--> 396\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32me:\\GitHub\\RAG\\Rag\\Rag\\lib\\site-packages\\langchain_core\\runnables\\base.py:4578\u001b[0m, in \u001b[0;36mRunnableLambda._invoke\u001b[1;34m(self, input, run_manager, config, **kwargs)\u001b[0m\n\u001b[0;32m   4574\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   4575\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecursion limit reached when invoking \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with input \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4576\u001b[0m         )\n\u001b[0;32m   4577\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRecursionError\u001b[39;00m(msg)\n\u001b[1;32m-> 4578\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4579\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4580\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpatch_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4581\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4582\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4583\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrecursion_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrecursion_limit\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4584\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4585\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4586\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cast(Output, output)\n",
      "File \u001b[1;32me:\\GitHub\\RAG\\Rag\\Rag\\lib\\site-packages\\langchain_core\\runnables\\base.py:3024\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3022\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3023\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3024\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3025\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[0;32m   3026\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32me:\\GitHub\\RAG\\Rag\\Rag\\lib\\site-packages\\langchain_core\\output_parsers\\base.py:193\u001b[0m, in \u001b[0;36mBaseOutputParser.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    188\u001b[0m     \u001b[38;5;28minput\u001b[39m: Union[\u001b[38;5;28mstr\u001b[39m, BaseMessage],\n\u001b[0;32m    189\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    190\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    191\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[0;32m    192\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28minput\u001b[39m, BaseMessage):\n\u001b[1;32m--> 193\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minner_input\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_result\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatGeneration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minner_input\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    202\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_config(\n\u001b[0;32m    203\u001b[0m             \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_result([Generation(text\u001b[38;5;241m=\u001b[39minner_input)]),\n\u001b[0;32m    204\u001b[0m             \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m    205\u001b[0m             config,\n\u001b[0;32m    206\u001b[0m             run_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    207\u001b[0m         )\n",
      "File \u001b[1;32me:\\GitHub\\RAG\\Rag\\Rag\\lib\\site-packages\\langchain_core\\runnables\\base.py:1927\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[1;34m(self, func, input, config, run_type, serialized, **kwargs)\u001b[0m\n\u001b[0;32m   1923\u001b[0m     context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[0;32m   1924\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, child_config)\n\u001b[0;32m   1925\u001b[0m     output \u001b[38;5;241m=\u001b[39m cast(\n\u001b[0;32m   1926\u001b[0m         Output,\n\u001b[1;32m-> 1927\u001b[0m         context\u001b[38;5;241m.\u001b[39mrun(\n\u001b[0;32m   1928\u001b[0m             call_func_with_variable_args,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m   1929\u001b[0m             func,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m   1930\u001b[0m             \u001b[38;5;28minput\u001b[39m,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m   1931\u001b[0m             config,\n\u001b[0;32m   1932\u001b[0m             run_manager,\n\u001b[0;32m   1933\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1934\u001b[0m         ),\n\u001b[0;32m   1935\u001b[0m     )\n\u001b[0;32m   1936\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1937\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32me:\\GitHub\\RAG\\Rag\\Rag\\lib\\site-packages\\langchain_core\\runnables\\config.py:396\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[1;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[0;32m    395\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[1;32m--> 396\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32me:\\GitHub\\RAG\\Rag\\Rag\\lib\\site-packages\\langchain_core\\output_parsers\\base.py:194\u001b[0m, in \u001b[0;36mBaseOutputParser.invoke.<locals>.<lambda>\u001b[1;34m(inner_input)\u001b[0m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    188\u001b[0m     \u001b[38;5;28minput\u001b[39m: Union[\u001b[38;5;28mstr\u001b[39m, BaseMessage],\n\u001b[0;32m    189\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    190\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    191\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[0;32m    192\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28minput\u001b[39m, BaseMessage):\n\u001b[0;32m    193\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_config(\n\u001b[1;32m--> 194\u001b[0m             \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_result\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatGeneration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minner_input\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    197\u001b[0m             \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m    198\u001b[0m             config,\n\u001b[0;32m    199\u001b[0m             run_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    200\u001b[0m         )\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    202\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_config(\n\u001b[0;32m    203\u001b[0m             \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_result([Generation(text\u001b[38;5;241m=\u001b[39minner_input)]),\n\u001b[0;32m    204\u001b[0m             \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m    205\u001b[0m             config,\n\u001b[0;32m    206\u001b[0m             run_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    207\u001b[0m         )\n",
      "File \u001b[1;32me:\\GitHub\\RAG\\Rag\\Rag\\lib\\site-packages\\langchain_core\\output_parsers\\openai_tools.py:298\u001b[0m, in \u001b[0;36mPydanticToolsParser.parse_result\u001b[1;34m(self, result, partial)\u001b[0m\n\u001b[0;32m    296\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    297\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 298\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    299\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfirst_tool_only:\n\u001b[0;32m    300\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pydantic_objects[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m pydantic_objects \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32me:\\GitHub\\RAG\\Rag\\Rag\\lib\\site-packages\\langchain_core\\output_parsers\\openai_tools.py:293\u001b[0m, in \u001b[0;36mPydanticToolsParser.parse_result\u001b[1;34m(self, result, partial)\u001b[0m\n\u001b[0;32m    288\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    289\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTool arguments must be specified as a dict, received: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    290\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mres[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124margs\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    291\u001b[0m         )\n\u001b[0;32m    292\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m--> 293\u001b[0m     pydantic_objects\u001b[38;5;241m.\u001b[39mappend(name_dict[res[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m]](\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mres[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margs\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ValidationError, \u001b[38;5;167;01mValueError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    295\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m partial:\n",
      "File \u001b[1;32me:\\GitHub\\RAG\\Rag\\Rag\\lib\\site-packages\\pydantic\\v1\\main.py:341\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[1;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[0;32m    339\u001b[0m values, fields_set, validation_error \u001b[38;5;241m=\u001b[39m validate_model(__pydantic_self__\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, data)\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[1;32m--> 341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    343\u001b[0m     object_setattr(__pydantic_self__, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__dict__\u001b[39m\u001b[38;5;124m'\u001b[39m, values)\n",
      "\u001b[1;31mValidationError\u001b[0m: 2 validation errors for KPIRequest\naggregation\n  unexpected value; permitted: 'mean', 'min', 'max', 'var', 'std', 'sum' (type=value_error.const; given=; permitted=('mean', 'min', 'max', 'var', 'std', 'sum'))\nstep\n  none is not an allowed value (type=type_error.none.not_allowed)"
     ]
    }
   ],
   "source": [
    "print(chain.invoke({\"query\": \"\"\" what is a machine?\"\"\"}))\n",
    "#bunny expert is back..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chain.invoke({\"query\": \"\"\" what are eyes?\"\"\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm happy to provide some bunny-related information, but I must inform you that there isn't a widely recognized \"bunny KPI\" (Key Performance Indicator). However, if we were to create one for the sake of fun, here's a possible example:\n",
      "\n",
      "Let's say our bunny KPI is the number of hours of playtime or exercise provided to bunnies in our care (e.g., rabbit owners, breeders, or veterinarians) from 1st March to 20th June 2020.\n",
      "\n",
      "To calculate this, we would need some data on the total hours spent playing with or exercising bunnies during that period. Since I don't have any specific data, I'll create a hypothetical example:\n",
      "\n",
      "**Bunny KPI: Total Hours of Playtime**\n",
      "\n",
      "* Assumed average playtime per bunny per day: 1 hour\n",
      "* Number of days from 1st March to 20th June 2020: approximately 90 days\n",
      "* Estimated number of bunnies in our care during that period: 100\n",
      "\n",
      "Total hours of playtime = 90 days x 1 hour/day x 100 bunnies = 9,000 hours\n",
      "\n",
      "However, please note that this is a completely fictional example and not based on any real data.\n",
      "\n",
      "If you're interested in tracking actual KPIs related to rabbits or bunny-related activities, I'd be happy to help with that as well!\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke({\"query\": \"\"\" tell me what is the bunny KPI \n",
    "                    from 1st march to 20th june 2020?\"\"\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result  Explanation\n",
    "\n",
    "Here i am hopping some information getting from KPI engine -\n",
    "* resut= the numbers after aggregation\n",
    "* comments = the comments on the result like it's maybe some percentage or trend of the result if it's a date range\n",
    "* reason= the result it increase decrese etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for initial query "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Based on the following inputs, generate a detailed and natural language explanation:\n",
    "    - KPI Name: {kpi_name}\n",
    "    - KPI Value: {result}\n",
    "    - Comparison: {comments}\n",
    "    - Docs: {docs}\n",
    "    - Reason: {reason}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# explanation for KPI result\n",
    "def explain_kpi_result(kpi_name, machine_op_pairs, aggregation, start_date, end_date, result, docs, model):\n",
    "    dynamic_explanation_prompt = ChatPromptTemplate.from_template(template=\"\"\"\n",
    "    Based on the following inputs, generate a detailed and natural language explanation:\n",
    "    - KPI Name: {kpi_name}\n",
    "    - Machines-Operations pairs: {machine_op_pairs}\n",
    "    - Aggregation: {aggregation}\n",
    "    - Start date: {start_date}\n",
    "    - End date: {end_date}\n",
    "    - KPI Value: {result}\n",
    "    - Docs: {docs}\n",
    "\n",
    "    Generate an explanation as if explaining to a user who asked a relevant question. Be clear, concise, and informative.\n",
    "    \"\"\")\n",
    "    prompt_data = {\n",
    "        \"kpi_name\": kpi_name,\n",
    "        \"machine_op_pairs\": machine_op_pairs,\n",
    "        \"aggregation\": aggregation,\n",
    "        \"start_date\": start_date,\n",
    "        \"end_date\": end_date,\n",
    "        \"result\": result,\n",
    "        \"docs\": docs,\n",
    "    }\n",
    "\n",
    "    explanation = dynamic_explanation_prompt | model | StrOutputParser()\n",
    "    return explanation.invoke(prompt_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Explanation:\n",
      "Here's a detailed and natural language explanation of the KPI value:\n",
      "\n",
      "\"Yes, I can explain why our Total Energy Consumption for this period is 22 kWh. This year, compared to the same period last year, we saw an increase of 10%. The reason behind this increase is due to the increased workload on January 5th.\n",
      "\n",
      "During that day, we experienced a surge in activity, which resulted in higher energy consumption as our systems and equipment were under more strain than usual. This led to a temporary increase in energy usage, causing our total consumption for the period to be slightly higher than anticipated.\n",
      "\n",
      "It's worth noting that this one-time event had a significant impact on our energy usage, but we're taking steps to mitigate such occurrences in the future by optimizing our systems and processes to better manage workload fluctuations. We'll continue to monitor our energy consumption closely and work towards reducing waste and improving efficiency.\"\n",
      "\n",
      "I hope this helps! Let me know if you have any further questions or need additional clarification.\n"
     ]
    }
   ],
   "source": [
    "# Example  \n",
    "kpi_name = \"Total Energy Consumption\" # we already have this info\n",
    "result = \"22 kWh\" # i want this to get from kpi engine\n",
    "comments = \"10% higher than the same period last year\" # i want this to get from kpi engine\n",
    "reason = \"Increased workload on January 5th\" # i want this to get from kpi engine\n",
    "\n",
    "result_explanation = explain_kpi_result(kpi_name=kpi_name, result=result, \n",
    "                                         comments=comments, reason=reason, model=model)\n",
    "\n",
    "print(f\"Generated Explanation:\\n{result_explanation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For followup query getting from user probably here we will need to knowladge base to guide the user to look at specefic context or properties of kpi to make them understand why it's might increased 10% or so or what can be done further and so on\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for follow-up discussions\n",
    "def follow_up(kpi_name, result, machine_op_pairs, aggregation, start_date, end_date, docs, user_input, model):\n",
    "\n",
    "    # Prompt template for follow-up query\n",
    "    follow_up_prompt_template = ChatPromptTemplate.from_template(\n",
    "        template=\"\"\"\n",
    "        The user has requested further discussion about the KPI analysis. Based on the context:\n",
    "        - KPI Name: {kpi_name}\n",
    "        - Machines-Operations pairs: {machine_op_pairs}\n",
    "        - Aggregation: {aggregation}\n",
    "        - Start date: {start_date}\n",
    "        - End date: {end_date}\n",
    "        - KPI Value: {result}\n",
    "        - Docs: {docs}\n",
    "\n",
    "        The user said: \"{user_input}\"\n",
    "\n",
    "        Generate a detailed follow-up response. Offer actionable insights or ask clarifying questions to continue the discussion.\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    print(machine_op_pairs)\n",
    "    prompt_data = {\n",
    "        \"kpi_name\": kpi_name,\n",
    "        \"machine_op_pairs\": machine_op_pairs,\n",
    "        \"aggregation\": aggregation,\n",
    "        \"start_date\": start_date,\n",
    "        \"end_date\": end_date,\n",
    "        \"result\": result,\n",
    "        \"docs\": docs,\n",
    "        \"user_input\": user_input,\n",
    "    }\n",
    "    follow_up_response = follow_up_prompt_template | model | StrOutputParser()\n",
    "    return follow_up_response.invoke(prompt_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Follow-Up Response:\n",
      "Based on the provided context, I'd like to drill down into the KPI analysis further.\n",
      "\n",
      "Firstly, it's essential to acknowledge that an increase of 10% in total energy consumption compared to the same period last year is a notable change. However, we need to understand what this increase signifies and whether it's a short-term anomaly or a more significant trend.\n",
      "\n",
      "Given the reason for the increase - increased workload on January 5th - it might be helpful to explore how this specific event impacted energy consumption. Are there any specific activities, systems, or equipment that were utilized extensively during this period? Understanding the root cause of the increase can help in identifying potential opportunities for optimization or reduction.\n",
      "\n",
      "Here are a few follow-up questions to continue the discussion:\n",
      "\n",
      "1. Can you provide more details about the increased workload on January 5th, such as specific tasks, projects, or systems involved?\n",
      "2. Are there any other factors that could have contributed to the energy consumption increase during this period, such as weather patterns, equipment maintenance, or upgrades?\n",
      "3. Have we considered analyzing historical data to identify if this anomaly is a one-off event or part of a larger trend?\n",
      "\n",
      "Additionally, it might be beneficial to consider some potential actions to mitigate the impact of future increases in workload:\n",
      "\n",
      "1. Can we explore ways to optimize energy consumption during periods of high activity, such as implementing energy-efficient solutions or adjusting work schedules?\n",
      "2. Are there any opportunities to reduce peak demand by using shift-based power supplies, smart grid management systems, or other load management strategies?\n",
      "\n",
      "To further refine our understanding of the KPI analysis, I'd like to know:\n",
      "\n",
      "1. Are there any plans in place to address this trend and prevent similar increases in energy consumption?\n",
      "2. Have we considered conducting a full-scale energy audit to identify areas for improvement and opportunities for optimization?\n",
      "\n",
      "By exploring these questions and insights, we can work together to develop strategies that will help us mitigate the impact of future increases in workload and optimize our energy consumption.\n",
      "\n",
      "What are your thoughts on this?\n"
     ]
    }
   ],
   "source": [
    "# Example \n",
    "user_input = \"Yes, discuss further\"\n",
    "follow_up_response = follow_up(\n",
    "    kpi_name=\"Total Energy Consumption\",\n",
    "    result=\"22 kWh\",\n",
    "    comments=\"10% higher than the same period last year\",\n",
    "    reason=\"Increased workload on January 5th\",\n",
    "    user_input=user_input,\n",
    "    model=model\n",
    ")\n",
    "\n",
    "print(f\"Follow-Up Response:\\n{follow_up_response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from RAG import Rag\n",
    "question = input(\"Hello, how can I help you today?\")\n",
    "rag=Rag(model=\"llama3.2\")\n",
    "structured_query=rag.routing().invoke({\"query\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['query'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template=\"Route the user's query to one of these: the KPI query constructor, the bunny expert, or 'else' if not strictly related to them.\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['query'], input_types={}, partial_variables={}, template='{query}'), additional_kwargs={})])\n",
       "| RunnableBinding(bound=ChatOllama(model='llama3.2'), kwargs={'tools': [{'type': 'function', 'function': {'name': 'RouteQuery', 'description': 'Route query to destination.', 'parameters': {'type': 'object', 'properties': {'destination': {'enum': ['KPI query', 'KPI trend', 'bunny', 'else'], 'type': 'string'}}, 'required': ['destination']}}}], 'tool_choice': 'any'}, config={}, config_factories=[])\n",
       "| JsonOutputKeyToolsParser(first_tool_only=True, key_name='RouteQuery')\n",
       "| RunnableLambda(itemgetter('destination'))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag.routing_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Large Capacity Cutting Machine', 'Small Capacity Cutting Machine']\n"
     ]
    }
   ],
   "source": [
    "print(structured_query.machine_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n",
      "c:\\Users\\Sube-\\OneDrive\\Desktop\\RAG5\\RAG.py:6: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  from StructuredOutput import KPIRequest, KPITrend, RouteQuery\n"
     ]
    }
   ],
   "source": [
    "from RAG import Rag\n",
    "engine_output= \"0.75 KWh\"\n",
    "rag=Rag(model=\"llama3.2\")\n",
    "path=\"./KB_original.owl\"\n",
    "vectorstore = rag.load_documents(path=path)\n",
    "question = \"I want you to provide information about the weekly total average for the energy consumption KPI of the metal cutting machine when idle from 2023 to 2024?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "docs=vectorstore.similarity_search(query=question, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_query=Rag(model=\"llama3.2\").routing().invoke({\"query\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('metal cutting machine', 'idle')]\n",
      "energy consumption\n"
     ]
    }
   ],
   "source": [
    "pairs = zip(structured_query.machine_names, structured_query.operation_names)\n",
    "l = list(pairs)\n",
    "print(l)\n",
    "print(structured_query.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_explanation = rag.explain_kpi_result(kpi_name=structured_query.name, machine_op_pairs=l,aggregation=structured_query.aggregation, start_date=structured_query.start_date, end_date=structured_query.end_date, result=engine_output, \n",
    "                                        docs=rag.format_docs(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'd be happy to help you understand the provided KPI (Key Performance Indicator) inputs.\n",
      "\n",
      "**Your Question:** You want to know more about the \"energy consumption\" KPI, specifically how it's calculated and what it measures.\n",
      "\n",
      "**Answer:**\n",
      "\n",
      "The \"energy consumption\" KPI is a metric that measures the average energy usage of all machine-operation pairs over a specific period. In this case, the period starts on January 1st, 2023, and ends on November 25th, 2024.\n",
      "\n",
      "To calculate this KPI, we need to consider the machines' operations and their corresponding energy consumption values. For example, if a \"metal cutting machine\" is idle for most of the time, it's likely that its energy consumption will be lower than a machine that's in use.\n",
      "\n",
      "The aggregation method used here is \"mean\", which means that we'll calculate the average energy consumption across all machines and operations over the specified period.\n",
      "\n",
      "**What does this KPI measure?**\n",
      "\n",
      "In essence, the \"energy consumption\" KPI measures the average amount of energy used by machines to perform their operations over a set time frame. This metric helps organizations understand their energy usage patterns, identify areas for improvement, and make informed decisions about energy management and cost optimization.\n",
      "\n",
      "For example, if the calculated value is 0.75 kWh, it means that on average, all machine-operation pairs consumed 0.75 kilowatt-hours of energy over the specified period.\n",
      "\n",
      "**Why is this KPI important?**\n",
      "\n",
      "This KPI is crucial for organizations to manage their energy costs effectively, reduce waste, and minimize their environmental impact. By tracking energy consumption patterns, organizations can identify opportunities to optimize energy usage, invest in more efficient equipment, and make data-driven decisions about their energy management strategies.\n",
      "\n",
      "I hope this explanation helps you understand the \"energy consumption\" KPI better!\n"
     ]
    }
   ],
   "source": [
    "print(result_explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('metal cutting machine', 'idle')]\n"
     ]
    }
   ],
   "source": [
    "user_input = \"Yes, discuss further\"\n",
    "follow_up_response = rag.follow_up(\n",
    "    kpi_name=structured_query.name,\n",
    "    result=engine_output,\n",
    "    machine_op_pairs=l,\n",
    "    aggregation=structured_query.aggregation,\n",
    "    start_date=structured_query.start_date,\n",
    "    end_date=structured_query.end_date,\n",
    "    docs=rag.format_docs(docs),\n",
    "    user_input=user_input,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context and KPI analysis, I'd like to dive deeper into the following aspects:\n",
      "\n",
      "1. **Energy Consumption KPI**: The current energy consumption KPI measures the average energy consumption of all machine-operations pairs over a specified period (01/01/23 - 25/11/24). The value is set at 0.75 kWh.\n",
      "\n",
      "Actionable Insights:\n",
      "- Consider exploring trends in energy consumption patterns throughout the year to identify seasonal fluctuations or opportunities for improvement.\n",
      "- Investigate potential correlations between energy consumption and other KPIs, such as production volume or machine utilization rates.\n",
      "\n",
      "2. **Machine Operations**: The pair 'metal cutting machine' is currently marked as idle, which might be an oversight given its operational status.\n",
      "\n",
      "Clarifying Questions:\n",
      "- Are there specific reasons why the metal cutting machine was incorrectly marked as idle?\n",
      "- Can we identify a pattern or trend in machine operation statuses that could help optimize energy consumption?\n",
      "\n",
      "3. **Aggregation Method**: The aggregation method for this KPI is set to 'mean'. This might be suitable if the goal is to calculate an average energy consumption rate.\n",
      "\n",
      "Alternative Aggregation Methods:\n",
      "- Consider exploring other aggregation methods, such as 'sum' or 'max', depending on the specific requirements of your analysis.\n",
      "- If the objective is to track cumulative energy consumption over time, using a 'cumulative sum' method could provide more insightful results.\n",
      "\n",
      "4. **Potential Improvements**: With this KPI in mind, what are some potential strategies for reducing energy consumption?\n",
      "\n",
      "Actionable Insights:\n",
      "- Investigate possible ways to optimize machine settings or processes that contribute to lower energy consumption.\n",
      "- Identify opportunities for upgrading or replacing less efficient equipment with newer models that prioritize energy efficiency.\n",
      "\n",
      "5. **Documentation and Documentation**: The provided documentation offers a broad overview of various KPIs and their definitions but does not delve deeply into the specifics of the 'energy consumption' KPI.\n",
      "\n",
      "Clarifying Questions:\n",
      "- Are there any additional metrics, data points, or insights related to energy usage that could enhance this analysis?\n",
      "- Can we further refine our understanding of what factors influence energy consumption in our specific production environment?\n",
      "\n",
      "By exploring these points and gathering more information, we can gain a deeper comprehension of the 'energy consumption' KPI's significance, potential areas for improvement, and opportunities for optimizing our production processes.\n"
     ]
    }
   ],
   "source": [
    "print(follow_up_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The answer is 0.75, which appears to be related to a KPI (Key Performance Indicator) for large capacity cutting machines.\n",
      "\n",
      "After analyzing the provided documents, I found that there are two relevant KPIs: \"average_cycle_time_avg\" and \"good_cycles_avg\". However, none of these directly have an average or value of 0.75.\n",
      "\n",
      "But, upon closer inspection, I noticed that the KPI \"consumption_sum\" has a similar structure to the other two KPIs, with the abbreviation Dsumtmo indicating the formula for calculation: Asummo[ Asumt[ Dsumtmo ]]. \n",
      "\n",
      "The answer 0.75 seems related to this \"consumption_sum\" KPI. Since there's no clear indication of which value, such as kWh, is being used in the formula for consumption_sum, and since it doesn't correspond directly with average_cycle_time_avg or good_cycles_avg, I can only guess that it might be a specific instance related to one of these KPIs.\n",
      "\n",
      "For example, if consumption_sum = 0.75 times some factor (like the maximum time used for operations) then 0.75 would represent the proportion or ratio of some value in consumption_sum relative to its maximum, and therefore could be interpreted as an average.\n",
      "\n",
      "However, without further context or clarification on what this answer represents, it's difficult to provide a definitive explanation for how 0.75 relates to these KPIs.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "            template=\"The answer of the query is {engine_output}, explain it using these informations: {docs}.\"\n",
    "            \n",
    "        )\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "#chain = {\"docs\": format_docs}| prompt | rag.get_model() | StrOutputParser()\n",
    "\n",
    "question = \"I want you to provide information about the weekly average for the energy consumption of the of Large Capacity Cutting Machine when idle and Small Capacity Cutting Machine when working to today?\"\n",
    "\n",
    "docs = vectorstore.similarity_search(query=question, k=5)\n",
    "prompt_data = {\n",
    "        \"docs\": docs,\n",
    "        \"engine_output\": engine_output,\n",
    "    }\n",
    "follow_up_response = prompt | rag.get_model() | StrOutputParser()\n",
    "print(follow_up_response.invoke(prompt_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': './KB_original.owl'}, page_content='large_capacity_cutting_machine_1\\n\\naverage_cycle_time_avg\\n\\nAmeanmo[ Ameant[ Daverage_cycle_time_avgtmo ]]\\n\\nThis KPI measures the average time it takes to complete a single machine process or task from start to finish\\n\\ns\\n\\nPure KPI\\n\\naverage_cycle_time_avg\\n\\nfloor_1\\n\\nast-o8xtn5xa8y87'),\n",
       " Document(metadata={'source': './KB_original.owl'}, page_content='This KPI measure the average energy consumption of all machine-operations pairs\\n\\nkWh\\n\\nPure KPI\\n\\nconsumption_avg\\n\\ntime_sum\\n\\nAsummo[ Asumt[ Dtime_sumtmo ]]\\n\\nThis KPI measures the cumulative time each machine used to perform the associated operation for every machine-operation pairs.\\n\\ns'),\n",
       " Document(metadata={'source': './KB_original.owl'}, page_content='riveting_machine\\n\\nA subclass of energy_kpi that focuses on metrics specifically related to energy consumption. Instances of this class represent quantifiable indicators used to measure and evaluate the amount of energy consumed by a system, process, or entity over a specified period.'),\n",
       " Document(metadata={'source': './KB_original.owl'}, page_content='downtime_kpi\\n\\nconsumption_sum\\n\\nAsummo[ Asumt[ Dconsumption_sumtmo ] ]\\n\\nThis KPI measure the cumulative energy consumption of all machine-operations pairs\\n\\nkWh\\n\\nPure KPI\\n\\nconsumption_sum\\n\\nfloor_1\\n\\nast-pwpbba0ewprp\\n\\nassembly_machine_1\\n\\ncost_sum\\n\\nAsummo[ Asumt[ Dcost_sumtmo ] ]'),\n",
       " Document(metadata={'source': './KB_original.owl'}, page_content='time_max\\n\\nfloor_2\\n\\nast-6votor3o4i9l\\n\\nlarge\\n\\nlarge_capacity_cutting_machine_2\\n\\ngood_cycles_avg\\n\\nAmeanmo[ Ameant[ Dgood_cycles_avgtmo ]]')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n",
      "c:\\Users\\Giamm\\Desktop\\RAG2\\RAG5\\RAG.py:6: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  from StructuredOutput import KPIRequest, KPITrend, RouteQuery\n"
     ]
    }
   ],
   "source": [
    "from RAG import Rag\n",
    "rag= Rag(model=\"llama3.2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result explanation: I'd be happy to help you understand the given KPI (Key Performance Indicator) details.\n",
      "\n",
      "**What is this KPI about?**\n",
      "\n",
      "The KPI name \"energy_consumption_metal_cutting_machine_idle\" measures the average energy consumption of a specific machine when it's not actively being used for metal cutting operations. In other words, it calculates the energy consumed by the machine while it's idle or standing by.\n",
      "\n",
      "**How is this KPI calculated?**\n",
      "\n",
      "The KPI is aggregated using the \"mean\" method, which means that all idle time instances from the specified date range (01/01/23 to 26/11/24) are averaged together to get an average energy consumption value. The result of this calculation is given as 0.75 kWh.\n",
      "\n",
      "**What does it mean?**\n",
      "\n",
      "The KPI provides valuable insights into the machine's energy efficiency when not in use. A lower energy consumption value indicates that the machine is more efficient and uses less energy while idle, which can help reduce overall energy costs and environmental impact. On the other hand, a higher value might indicate areas for improvement to optimize machine utilization and reduce waste.\n",
      "\n",
      "**Context and relevance**\n",
      "\n",
      "This KPI seems to be part of a larger system or process related to metal cutting machines in a manufacturing environment. It's likely used as a performance metric to monitor energy efficiency and optimize machine operations, which can have significant implications for cost management, environmental sustainability, and overall productivity.\n",
      "\n",
      "Based on the provided context, I will generate a detailed follow-up response that offers actionable insights and asks clarifying questions to continue the discussion.\n",
      "\n",
      "**Summary of Key Points**\n",
      "\n",
      "To summarize, we have:\n",
      "\n",
      "* A KPI named \"energy_consumption_metal_cutting_machine_idle\" with an aggregation type of \"mean\"\n",
      "* No machines-operations pairs are specified\n",
      "* The time period is from January 1st, 2023, to November 26th, 2024\n",
      "* The KPI value for this metric is 0.75 kWh\n",
      "\n",
      "**Insights and Recommendations**\n",
      "\n",
      "Based on the provided information, here are some insights and recommendations that can be derived:\n",
      "\n",
      "1. **Energy Efficiency**: With a KPI value of 0.75 kWh, it appears that metal cutting machines in our system have relatively low energy consumption during idle times. However, to gain a better understanding of this metric, we would need to analyze the context of \"idle\" time and how it is defined within the system.\n",
      "2. **Comparison with Other KPIs**: To put this metric into perspective, we could compare it with other KPIs related to energy consumption, such as the average cost of energy used in production or the maximum cost of energy used in production. This comparison would help identify areas where our metal cutting machines are more or less efficient than others.\n",
      "3. **Identify Machines with High Idle Time**: Since no machines-operations pairs are specified, we cannot directly analyze which machines have high idle times. However, if we were to obtain this information, it could help us prioritize efforts to optimize energy efficiency in those machines.\n",
      "\n",
      "**Clarifying Questions**\n",
      "\n",
      "To further discuss the KPI and gain a better understanding of its context, I would like to ask:\n",
      "\n",
      "1. Can you provide more details on what is considered \"idle\" time for metal cutting machines? Is it when the machine is not being actively used or when it is waiting for a task to be completed?\n",
      "2. Are there any other KPIs related to energy consumption that we could compare this metric with to gain a better understanding of our system's energy efficiency?\n",
      "3. Do you have any plans to optimize or improve the energy efficiency of our metal cutting machines, and if so, what steps do you plan to take?\n",
      "\n",
      "**Next Steps**\n",
      "\n",
      "Based on the discussion, I recommend the following next steps:\n",
      "\n",
      "1. Gather more information about the \"idle\" time for metal cutting machines.\n",
      "2. Compare this KPI with other relevant KPIs related to energy consumption.\n",
      "3. Discuss plans to optimize or improve energy efficiency in our metal cutting machines.\n",
      "\n",
      "Please let me know if you have any additional insights, questions, or recommendations to share. I am here to help facilitate a productive discussion!\n",
      "\n",
      "Based on the provided context, I will generate a detailed follow-up response that offers actionable insights and asks clarifying questions to continue the discussion.\n",
      "\n",
      "**Executive Summary**\n",
      "\n",
      "The energy_consumption_metal_cutting_machine_idle KPI analysis provides valuable insights into the average energy consumption of metal cutting machines during idle periods. The aggregated value of 0.75 kWh per machine-operation pair indicates a moderate level of energy consumption during downtime. This report aims to provide actionable recommendations for optimizing energy efficiency and reducing waste.\n",
      "\n",
      "**Methodology**\n",
      "\n",
      "The analysis is based on the provided data, which includes:\n",
      "\n",
      "1. KPI Name: energy_consumption_metal_cutting_machine_idle\n",
      "2. Machines-Operations pairs: []\n",
      "3. Aggregation: mean\n",
      "4. Start date: 01/01/23\n",
      "5. End date: 26/11/24\n",
      "6. KPI Value: 0.75 kWh\n",
      "\n",
      "**Insights**\n",
      "\n",
      "1. **Average energy consumption during idle periods**: The analysis reveals a moderate level of energy consumption during downtime, indicating that metal cutting machines may be consuming power even when not actively producing.\n",
      "2. **Potential for improvement**: With an average energy consumption value of 0.75 kWh, there is potential for optimization and reduction in waste. This could be achieved through implementing energy-saving measures, such as turning off machines during idle periods or using energy-efficient technologies.\n",
      "3. **Machine-operation pair analysis**: Since the Machines-Operations pairs list is empty, it may not be possible to analyze specific machine-operation pair data. However, this information would provide valuable insights into energy consumption patterns across different machines and operations.\n",
      "\n",
      "**Actionable Recommendations**\n",
      "\n",
      "1. Conduct an on-site audit to identify potential areas of energy waste and implement cost-saving measures.\n",
      "2. Review and optimize energy-efficient technologies, such as LED lighting or energy-recovery systems, to reduce power consumption during idle periods.\n",
      "3. Develop a schedule for machine maintenance and downtime management to minimize unnecessary energy consumption.\n",
      "4. Consider implementing a \"zero-waste\" policy, where machines are powered off during idle periods to eliminate unnecessary energy consumption.\n",
      "\n",
      "**Next Steps**\n",
      "\n",
      "To further discuss this report and explore potential solutions, I have a few clarifying questions:\n",
      "\n",
      "1. Are there any specific industries or sectors represented in the data?\n",
      "2. Can you provide more information about the Machines-Operations pairs list, as it appears to be empty? Would you like me to investigate possible reasons for this lack of data?\n",
      "3. Are there any existing energy efficiency initiatives or policies in place that could inform our recommendations?\n",
      "\n",
      "By answering these questions and discussing additional context, we can better understand the specific needs and challenges associated with optimizing energy consumption in metal cutting machines during idle periods.\n",
      "\n",
      "Please let me know if you would like to proceed with these recommendations or if you have any further questions.\n",
      "\n",
      "Based on the provided context, it appears that we are discussing a specific KPI (key performance indicator) related to energy consumption of metal cutting machines. Here's a summary of the information provided:\n",
      "\n",
      "* KPI Name: energy_consumption_metal_cutting_machine_idle\n",
      "* Aggregation: mean\n",
      "* Start date: 01/01/23\n",
      "* End date: 26/11/24\n",
      "* KPI Value: 0.75 kWh\n",
      "\n",
      "The user hasn't made any comments yet, so I'll provide some potential follow-up questions or actionable insights to continue the discussion:\n",
      "\n",
      "1. What is the goal of this KPI? Is it to measure energy efficiency, cost savings, or something else?\n",
      "2. Can you provide more context about the metal cutting machines and their operations? Are they used for a specific industry or process?\n",
      "3. How does this KPI value of 0.75 kWh compare to other KPI values or targets? Is there a baseline or benchmark for energy consumption?\n",
      "4. What is the aggregation method (mean) being used? Would a different aggregation method, such as sum or average, provide a better understanding of the data?\n",
      "5. Are there any specific documents or sources that provide more information about this KPI, its definitions, or related metrics?\n",
      "\n",
      "To offer actionable insights, here are some potential next steps:\n",
      "\n",
      "1. Analyze the KPI value and consider what factors might be contributing to the observed energy consumption pattern.\n",
      "2. Investigate how the KPI is being used in your organization or process. Are there any opportunities for improvement or optimization?\n",
      "3. Explore other related KPIs that might provide additional context or insights about energy efficiency, cost savings, or machine performance.\n",
      "\n",
      "Please let me know if you would like to proceed with any of these questions or insights, or if you have any further comments or requests!\n",
      "\n",
      "after end conversation maybe some explainbility related task can be done..\n"
     ]
    }
   ],
   "source": [
    "question=\"I want you to provide information about the weekly total average for the energy consumption KPI of the metal cutting machine when idle from 2023 to 2024?\"\n",
    "rag.run(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result explanation: I'd be happy to help you understand the energy consumption KPI.\n",
      "\n",
      "So, let's break down what we have here:\n",
      "\n",
      "**KPI Name:** Energy Consumption\n",
      "**Aggregation Method:** Mean (we're taking the average value)\n",
      "**Time Period:** We're looking at data from November 26th, 2024, onwards (since no end date is specified)\n",
      "\n",
      "Now, let's talk about what this KPI measures. The energy consumption KPI calculates the average amount of energy used by all machine-operation pairs over a specific period.\n",
      "\n",
      "In simpler terms, it's like calculating how much electricity or fuel your machines use on average during that time period.\n",
      "\n",
      "But here's the interesting part: we don't have any data about specific machines or operations (like a riveting machine or an assembly machine). That's because we haven't received any information about the individual machines or their usage patterns.\n",
      "\n",
      "However, we do have some related KPIs that might be useful:\n",
      "\n",
      "* `consumption_sum`: This measures the total amount of energy used by all machine-operation pairs over time.\n",
      "* `bad_cycles_avg` and `consumption_min`: These measure the average number of cycles where the output doesn't meet quality standards (for `bad_cycles_avg`) or the minimum energy consumption (for `consumption_min`) across all machine-operation pairs.\n",
      "\n",
      "These KPIs might provide more insights into your energy usage, but they're not directly comparable to our current `energy_consumption` KPI.\n",
      "\n",
      "If you have any specific questions about these KPIs or want to explore further, feel free to ask!\n",
      "\n",
      "Subject: Follow-up Report on KPI Analysis for Energy Consumption\n",
      "\n",
      "Dear [User],\n",
      "\n",
      "Thank you for your request to generate a report on the KPI analysis for energy consumption. Based on our previous discussion, I've compiled a detailed report that provides actionable insights and highlights areas of improvement.\n",
      "\n",
      "**Summary**\n",
      "\n",
      "Our analysis reveals that the average energy consumption of all machine-operations pairs has been consistently reported at 0.75 kWh since November 26, 2024. However, without an end date specified, we cannot determine if this value is representative of a long-term trend or a snapshot in time.\n",
      "\n",
      "**Insights and Recommendations**\n",
      "\n",
      "1. **Energy Efficiency**: The current energy consumption average of 0.75 kWh suggests that the system is operating efficiently. However, it's essential to monitor and analyze this KPI regularly to identify areas for improvement.\n",
      "2. **Comparison with Other KPIs**: We analyzed other KPIs related to energy consumption, such as cost_sum, consumption_min, and non_operative_time. These metrics provide a more comprehensive view of the system's energy usage patterns. For instance, consumption_sum indicates a cumulative energy consumption of [insert value], while non_operative_time shows a total time spent not performing productive operations.\n",
      "3. **Document Analysis**: Our analysis of the provided documents reveals that some KPIs are closely related to each other (e.g., average_cycle_time_avg and cost_sum). This suggests that these metrics might be interconnected, and understanding their relationships could provide valuable insights into optimizing energy consumption.\n",
      "\n",
      "**Actionable Questions**\n",
      "\n",
      "To further refine our analysis, I'd like to ask the following questions:\n",
      "\n",
      "1. What is the expected timeframe for monitoring energy consumption KPIs?\n",
      "2. Are there any specific machine-operations pairs that require special attention regarding energy efficiency or performance?\n",
      "3. Can we obtain more detailed information about the system's energy usage patterns (e.g., peak hours, energy sources used)?\n",
      "\n",
      "**Next Steps**\n",
      "\n",
      "Based on your feedback and answers to these questions, I can provide recommendations for:\n",
      "\n",
      "1. Establishing a baseline for long-term monitoring of energy consumption KPIs.\n",
      "2. Identifying areas for improvement and potential cost-saving measures.\n",
      "3. Refining our analysis to focus on the most critical machine-operations pairs.\n",
      "\n",
      "Please let me know if you have any additional information or insights that can help us refine our report. I'm here to assist you in providing actionable recommendations for improving energy efficiency and reducing costs.\n",
      "\n",
      "Best regards,\n",
      "\n",
      "[Your Name]\n",
      "\n",
      "after end conversation maybe some explainbility related task can be done..\n"
     ]
    }
   ],
   "source": [
    "question=\"I want you to provide information about the weekly total average for the energy consumption KPI of the metal cutting machine when idle from 2023 to 2024?\"\n",
    "rag.run(question)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchainvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
